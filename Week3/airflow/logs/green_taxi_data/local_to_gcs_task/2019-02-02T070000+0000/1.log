[2022-04-20 01:02:00,509] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: green_taxi_data.local_to_gcs_task scheduled__2019-02-02T07:00:00+00:00 [queued]>
[2022-04-20 01:02:00,515] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: green_taxi_data.local_to_gcs_task scheduled__2019-02-02T07:00:00+00:00 [queued]>
[2022-04-20 01:02:00,515] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-20 01:02:00,516] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-20 01:02:00,516] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-20 01:02:00,524] {taskinstance.py:1270} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2019-02-02 07:00:00+00:00
[2022-04-20 01:02:00,527] {standard_task_runner.py:52} INFO - Started process 208 to run task
[2022-04-20 01:02:00,528] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'green_taxi_data', 'local_to_gcs_task', 'scheduled__2019-02-02T07:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag_v02.py', '--cfg-path', '/tmp/tmpwxh7ocf_', '--error-file', '/tmp/tmpjilagjk4']
[2022-04-20 01:02:00,529] {standard_task_runner.py:80} INFO - Job 17: Subtask local_to_gcs_task
[2022-04-20 01:02:00,554] {logging_mixin.py:109} INFO - Running <TaskInstance: green_taxi_data.local_to_gcs_task scheduled__2019-02-02T07:00:00+00:00 [running]> on host 5e56b5a44db8
[2022-04-20 01:02:00,573] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-04-20 01:02:00,587] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=green_taxi_data
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2019-02-02T07:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-02-02T07:00:00+00:00
[2022-04-20 01:03:01,933] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 424, in connect
    tls_in_tls=tls_in_tls,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/local/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/usr/local/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/usr/local/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1074: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 450, in send
    timeout=timeout
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 786, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 389, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 341, in _raise_timeout
    self, url, "Read timed out. (read timeout=%s)" % timeout_value
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Read timed out. (read timeout=60)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 188, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion_gcs_dag_v02.py", line 48, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2735, in upload_from_filename
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2594, in upload_from_file
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2412, in _do_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2237, in _do_resumable_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/storage/blob.py", line 2112, in _initiate_resumable_upload
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 421, in initiate
    retriable_request, self._get_status_code, self._retry_strategy
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/_request_helpers.py", line 147, in wait_and_retry
    response = func()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/resumable_media/requests/upload.py", line 413, in retriable_request
    method, url, data=payload, headers=headers, timeout=timeout
  File "/home/airflow/.local/lib/python3.7/site-packages/google/auth/transport/requests.py", line 486, in request
    **kwargs
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 532, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Read timed out. (read timeout=60)
[2022-04-20 01:03:01,943] {taskinstance.py:1288} INFO - Marking task as UP_FOR_RETRY. dag_id=green_taxi_data, task_id=local_to_gcs_task, execution_date=20190202T070000, start_date=20220420T010200, end_date=20220420T010301
[2022-04-20 01:03:01,950] {standard_task_runner.py:98} ERROR - Failed to execute job 17 for task local_to_gcs_task (HTTPSConnectionPool(host='storage.googleapis.com', port=443): Read timed out. (read timeout=60); 208)
[2022-04-20 01:03:01,992] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-04-20 01:03:02,016] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
